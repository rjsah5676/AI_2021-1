{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ai_hw0512 (1).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z1ekgDsG3f1t","executionInfo":{"status":"ok","timestamp":1620813125666,"user_tz":-540,"elapsed":1780,"user":{"displayName":"이건모","photoUrl":"","userId":"03575563892051424086"}},"outputId":"2f7c9aee-6d70-4fcb-e3a0-770caace9ae5"},"source":["#성능을 높일 수 있는 방법 소개\n","\n","import numpy as np\n","from google.colab import drive\n","\n","#load train data and label\n","drive.mount('/content/drive')\n","train_data_path = \"/content/drive/My Drive/ai_data/train.npy\" # Your train data file\n","train_label_path = \"/content/drive/My Drive/ai_data/train_label.npy\" # Your train label file\n","test_query_path = \"/content/drive/My Drive/ai_data/test_query.npy\" # Your train data file\n","test_gallery_path = \"/content/drive/My Drive/ai_data/test_gallery.npy\" # Your train label file\n","\n","test_query_label_path = \"/content/drive/My Drive/ai_data/test_query_label.npy\" # \n","test_gallery_label_path = \"/content/drive/My Drive/ai_data/test_gallery_label.npy\" # \n","\n","\n","train_data = np.load(train_data_path, allow_pickle=True)\n","train_label = np.load(train_label_path, allow_pickle=True)  \n","\n","#test_query_label = np.load(test_query_label_path, allow_pickle=True)\n","\n","#쿼리는 질문(검색을 예로 들면 이미지 검색시 올리는 이미지)\n","test_gallery_label = np.load(test_gallery_label_path, allow_pickle=True)  \n","#데이터베이스에 저장되어있는 것들이 갤러리(찾고싶은 모든 이미지들이 저장된 곳)\n","#쿼리 1개를 전체 갤러리중 가장 가까운 하나를 찾는\n","#쿼리가 1개씩 들어올 때 가장 가까운 것을 갤러리에서 리턴해준다.\n","test_query_data = np.load(test_query_path, allow_pickle=True)\n","test_gallery_data = np.load(test_gallery_path, allow_pickle=True)\n","\n","num_train_data = train_data.shape[0]"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zi_CRigwB1Ed","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620813136468,"user_tz":-540,"elapsed":599,"user":{"displayName":"이건모","photoUrl":"","userId":"03575563892051424086"}},"outputId":"dda6f040-c21c-493a-b87e-215384a3a093"},"source":["print(train_data.shape) # train_data is a list\n","print(num_train_data) # the number of train_data\n","print(train_label.shape)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["(2000, 1, 512, 1, 1)\n","2000\n","(2000,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q0PR9AGXJjCF","executionInfo":{"status":"ok","timestamp":1620813523506,"user_tz":-540,"elapsed":623,"user":{"displayName":"이건모","photoUrl":"","userId":"03575563892051424086"}}},"source":["def getNearestNeibor(query, gallery): #쿼리 데이터와 갤러리 데이터를 비교하여 어떤 것과 가장 가까운지 인덱스 반환\n","  num_query = query.shape[0]\n","  num_gallery = gallery.shape[0]\n","  nn_idx = np.zeros(num_query)\n","  for q in range(num_query):  #2중 포문\n","    dist = np.zeros(num_gallery)\n","    for g in range(num_gallery):\n","      dist[g] = np.sqrt(np.sum((query[q,:] - gallery[g,:]) ** 2, axis=0)) #q번째 쿼리, g번째 갤러리 인덱싱 하여 하나하나 비교\n","      #axis를 통해 차원설정, distance 연산 dist의 갯수는 gallery의 수와 같다.\n","    nn_idx[q] = np.argmin(dist)\n","    #query하나를 모든 gallery와 비교하고 그 distance중 가장 작은 것을 저장\n","  return nn_idx"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"LXkbMqRFROoc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620813297631,"user_tz":-540,"elapsed":729,"user":{"displayName":"이건모","photoUrl":"","userId":"03575563892051424086"}},"outputId":"d18b8b4b-e1bf-4c2b-b935-adf5a9702d79"},"source":["import numpy as np\n","a=[1,2,3,4,5]\n","b=[1,3,5,7,9]\n","c=np.array(a)-np.array(b) #리스트 연산을 하기 위해 numpy로\n","print(c)\n","print(c**2)\n","print(np.sum(c**2))\n","print(np.sqrt((np.sum(c**2))))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[ 0 -1 -2 -3 -4]\n","[ 0  1  4  9 16]\n","30\n","5.477225575051661\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K9fzmh_pr3ZW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620813528644,"user_tz":-540,"elapsed":1816,"user":{"displayName":"이건모","photoUrl":"","userId":"03575563892051424086"}},"outputId":"d8a61803-5e0f-474d-d2dc-b936178a5809"},"source":["nn_idx = getNearestNeibor(test_query_data.squeeze(), test_gallery_data.squeeze())\n","print(test_query_data.shape)\n","print(test_query_data.squeeze().shape) #squeeze는 1을 모두 없앰(쓸모없는 것들)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["(1000, 1, 512, 1, 1)\n","(1000, 512)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8vFVVC2HsG5b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620813766514,"user_tz":-540,"elapsed":1765,"user":{"displayName":"이건모","photoUrl":"","userId":"03575563892051424086"}},"outputId":"1f60e1bc-8b63-44a4-8245-220dbd20ae54"},"source":["nn_idx = getNearestNeibor(test_query_data.squeeze(), test_gallery_data.squeeze())\n","print(test_query_data.shape)\n","#print(np.sum(test_query_label == test_gallery_label[np.int64(nn_idx)]))\n","#label끼리 비교하여 얼마나 정확한지 척도를 확인함\n","#nn_idx_rand = np.random.randint(1,100,1000)\n","#print(np.sum(test_query_label == test_gallery_label[np.int64(nn_idx_rand)]))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["(1000, 1, 512, 1, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"06ihfx-t453o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620813780689,"user_tz":-540,"elapsed":703,"user":{"displayName":"이건모","photoUrl":"","userId":"03575563892051424086"}},"outputId":"0d8f32d1-e838-4cff-ce7f-521c1be48705"},"source":["pred_test_gallery_label_txt = list_data = [str(int(a)).strip('\\n\\r') for a in test_gallery_label[np.int64(nn_idx)]]\n","print(pred_test_gallery_label_txt)\n","#print(train_data[0:10])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["['170', '200', '116', '92', '116', '116', '116', '56', '187', '116', '172', '88', '170', '32', '90', '116', '182', '158', '116', '36', '122', '60', '122', '188', '14', '116', '92', '86', '23', '71', '122', '122', '168', '103', '33', '18', '172', '45', '158', '14', '170', '71', '71', '146', '170', '86', '33', '103', '122', '196', '130', '116', '46', '116', '83', '170', '122', '182', '92', '30', '19', '182', '60', '71', '122', '116', '158', '14', '71', '188', '170', '116', '68', '188', '146', '158', '182', '116', '116', '122', '170', '116', '75', '116', '23', '14', '122', '116', '14', '116', '35', '32', '131', '116', '116', '170', '116', '92', '116', '122', '200', '77', '33', '122', '40', '71', '116', '158', '116', '122', '116', '170', '182', '33', '158', '40', '200', '116', '88', '116', '40', '116', '170', '122', '106', '116', '132', '185', '88', '62', '116', '116', '170', '19', '28', '170', '179', '116', '170', '14', '116', '157', '116', '157', '19', '14', '122', '122', '155', '116', '116', '71', '115', '98', '116', '32', '40', '114', '170', '64', '102', '55', '122', '79', '71', '170', '73', '45', '60', '142', '60', '71', '185', '185', '29', '182', '122', '170', '48', '19', '116', '116', '172', '116', '35', '116', '106', '88', '116', '98', '122', '116', '71', '116', '116', '185', '60', '116', '193', '158', '200', '33', '19', '33', '86', '122', '13', '33', '55', '146', '116', '116', '98', '33', '122', '30', '116', '71', '122', '86', '116', '33', '88', '40', '19', '116', '143', '116', '182', '122', '71', '116', '170', '32', '188', '40', '60', '116', '60', '22', '116', '88', '122', '170', '29', '122', '196', '116', '170', '146', '116', '187', '29', '122', '122', '122', '187', '131', '170', '60', '14', '60', '116', '158', '103', '103', '33', '122', '55', '122', '23', '182', '33', '19', '22', '56', '83', '116', '132', '60', '170', '14', '76', '122', '116', '182', '122', '170', '116', '116', '116', '170', '22', '14', '116', '33', '103', '27', '193', '168', '122', '14', '170', '122', '170', '158', '14', '71', '116', '22', '116', '55', '116', '71', '116', '116', '158', '116', '100', '116', '71', '60', '92', '116', '170', '36', '19', '88', '182', '170', '130', '158', '49', '158', '98', '29', '116', '170', '30', '86', '33', '56', '158', '56', '33', '172', '116', '187', '158', '116', '116', '19', '122', '14', '168', '116', '60', '170', '14', '116', '185', '116', '64', '18', '172', '157', '146', '116', '40', '62', '182', '98', '170', '170', '19', '14', '14', '116', '70', '146', '130', '64', '185', '103', '116', '115', '116', '116', '33', '102', '46', '116', '116', '88', '40', '172', '33', '83', '182', '58', '88', '22', '49', '182', '116', '158', '172', '116', '122', '14', '76', '172', '170', '116', '45', '98', '170', '170', '188', '116', '30', '116', '116', '116', '200', '33', '19', '22', '14', '68', '86', '122', '29', '116', '116', '116', '71', '22', '116', '122', '14', '116', '59', '30', '116', '170', '116', '88', '187', '116', '146', '116', '131', '56', '187', '172', '122', '116', '92', '22', '116', '14', '71', '116', '116', '116', '170', '187', '187', '116', '116', '146', '14', '33', '60', '29', '56', '158', '158', '116', '87', '116', '116', '116', '116', '116', '64', '132', '143', '116', '33', '170', '60', '116', '116', '116', '88', '116', '116', '185', '116', '116', '33', '116', '146', '71', '35', '35', '179', '158', '19', '33', '37', '130', '163', '102', '158', '14', '182', '29', '116', '116', '71', '116', '33', '88', '170', '71', '60', '146', '116', '170', '158', '198', '46', '71', '187', '170', '116', '122', '14', '71', '116', '22', '62', '122', '86', '130', '122', '170', '200', '116', '182', '170', '60', '158', '115', '170', '14', '14', '71', '60', '170', '116', '130', '71', '116', '122', '59', '88', '172', '66', '170', '170', '116', '83', '33', '60', '56', '170', '116', '73', '182', '196', '35', '33', '170', '98', '88', '23', '116', '116', '116', '116', '172', '158', '130', '146', '170', '86', '27', '116', '33', '122', '14', '32', '116', '122', '116', '32', '116', '103', '146', '116', '71', '185', '200', '22', '158', '22', '33', '158', '29', '22', '116', '116', '179', '116', '98', '116', '79', '76', '56', '98', '122', '103', '79', '14', '116', '22', '33', '99', '116', '76', '122', '116', '33', '105', '151', '88', '122', '116', '14', '116', '116', '33', '116', '200', '116', '116', '33', '130', '71', '116', '116', '116', '116', '92', '19', '103', '116', '170', '116', '146', '56', '23', '116', '116', '158', '29', '170', '22', '146', '182', '170', '116', '29', '18', '170', '193', '170', '200', '172', '200', '116', '116', '71', '116', '116', '86', '193', '87', '170', '56', '48', '33', '170', '103', '146', '170', '116', '116', '116', '116', '98', '116', '116', '83', '122', '170', '102', '71', '116', '116', '116', '200', '116', '103', '158', '116', '33', '116', '19', '116', '116', '182', '116', '116', '116', '19', '88', '103', '116', '116', '28', '120', '71', '83', '56', '116', '170', '29', '90', '158', '35', '170', '130', '56', '103', '71', '116', '170', '200', '122', '170', '71', '187', '71', '70', '40', '98', '23', '32', '170', '29', '29', '182', '122', '170', '88', '13', '19', '14', '172', '170', '86', '22', '122', '107', '130', '92', '88', '120', '116', '185', '198', '116', '33', '158', '120', '196', '116', '116', '116', '170', '193', '200', '118', '98', '170', '185', '158', '170', '22', '170', '116', '188', '22', '32', '88', '182', '116', '116', '86', '182', '98', '56', '56', '88', '116', '157', '46', '14', '116', '158', '58', '131', '187', '130', '116', '59', '172', '19', '170', '185', '49', '30', '22', '116', '188', '27', '122', '35', '35', '170', '60', '185', '88', '23', '187', '116', '179', '187', '116', '200', '157', '71', '196', '180', '187', '83', '200', '71', '120', '59', '163', '36', '116', '146', '158', '158', '60', '33', '122', '172', '170', '76', '40', '116', '102', '116', '88', '116', '187', '146', '92', '40', '179', '116', '182', '179', '14', '71', '196', '22', '22', '130', '188', '32', '170', '29', '130', '158', '200', '122', '116', '182', '158', '170', '170', '14', '170', '122', '122', '116', '116', '170', '103', '70', '19', '29', '30', '158', '116', '179', '98', '56', '170', '40', '116', '116', '196', '116', '116', '116', '116', '55', '88', '168', '14', '107', '122', '19', '88', '116', '88', '200', '14', '188', '14', '60', '60', '185', '56', '175', '88', '116', '198', '92', '132', '86', '14', '158', '62', '116', '170', '22', '122', '116', '22', '151', '170', '116', '22', '182', '86', '116', '27', '200', '79', '170', '116', '88', '13', '116', '116', '79', '102', '200', '71']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"brGnT7Sx74D2","executionInfo":{"status":"ok","timestamp":1620813833534,"user_tz":-540,"elapsed":3573,"user":{"displayName":"이건모","photoUrl":"","userId":"03575563892051424086"}}},"source":["#Import Libraries\n","#여기서 부터 딥러닝을 통해 인공지능 학습\n","\n","from __future__ import print_function\n","import argparse\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.autograd import Variable"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"wOKs4Y-t77hf","executionInfo":{"status":"ok","timestamp":1620814843464,"user_tz":-540,"elapsed":682,"user":{"displayName":"이건모","photoUrl":"","userId":"03575563892051424086"}}},"source":["class MyDataset(torch.utils.data.Dataset):\n","  #재정의\n","  def __init__(self, data, label=[]): #데이터와 레이블\n","    self.data = data\n","    self.label = label\n","    \n","  def __len__(self):  #데이터의 길이\n","    return self.data.shape[0]\n","\n","  def __getitem__(self, idx): #어떤걸 어떻게 가져올지\n","    if self.label == []:\n","      return self.data[idx, :, :, :]\n","    else:\n","      return self.data[idx, :, :, :], self.label[idx]\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"sOjuh-LM6ZQ8","executionInfo":{"status":"ok","timestamp":1620815306559,"user_tz":-540,"elapsed":604,"user":{"displayName":"이건모","photoUrl":"","userId":"03575563892051424086"}}},"source":["args={}\n","kwargs={}\n","args['batch_size']=8\n","args['test_batch_size']=16\n","args['epochs']=50  #The number of Epochs is the number of times you go through the full dataset. \n","args['lr']=0.1 #Learning rate is how fast it will decend. 얼만큼 많이 학습 될 것인지, 배치사이즈 증가시 러닝레이트 증가\n","args['momentum']=0.5 #SGD momentum (default: 0.5) Momentum is a moving average of our gradients (helps to keep direction).\n","#하산시 가속도를 얼마나 유지할 지\n","args['seed']=1 #random seed\n","args['log_interval']=1000 #프린트를 얼마나 자주 할 것인지, 값이 작을 수록 세밀하게 프린트\n","args['cuda']=False\n","\n","\n","\n","class Net(nn.Module):\n","    #This defines the structure of the NN.\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(512, 512, kernel_size=1) #인풋 사이즈, 아웃풋 사이즈\n","        self.bn1 = nn.BatchNorm2d(512) #입력 사이즈(정규화 해주는 레이어)\n","        self.conv2 = nn.Conv2d(512, 200, kernel_size=1)\n","        #self.conv2_drop = nn.Dropout2d()  #Dropout\n","        #self.fc1 = nn.Linear(512, 64)\n","        self.fc2 = nn.Linear(512, 200)\n","\n","    def forward(self, x):\n","        #Convolutional Layer/Pooling Layer/Activation\n","        x = F.relu( self.bn1(self.conv1(x)), 2) #non_linearity를 위해 ReLU\n","        #Convolutional Layer/Dropout/Pooling Layer/Activation\n","        #x = F.relu(self.conv2_drop(self.conv2(x)), 2)\n","        x = x.view(-1, 512) # 1들을 제거해줌 1,1,512,100 -> 512,100\n","        #Fully Connected Layer/Activation\n","        #x = F.relu(self.fc1(x))\n","        #x = F.dropout(x, training=self.training)\n","        #Fully Connected Layer/Activation\n","        x = self.fc2(x) #prediction을 위해 512 -> 200으로\n","        #Softmax gets probabilities. \n","        return F.log_softmax(x, dim=1) #확률의 합이 1이 되도록\n","\n","\n","\n","\n","def train(epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader): #배치 사이즈 만큼 가져옴\n","        if args['cuda']:\n","            data, target = data.cuda(), target.cuda()\n","        #Variables in Pytorch are differenciable.\n","        data, target = Variable(data), Variable(target)\n","        #This will zero out the gradients for this batch. \n","        optimizer.zero_grad()\n","        output = model(data) #포워드 함수 실행(아웃풋은 최종 결과 값인 확률 값)\n","        # Calculate the loss The negative log likelihood loss. It is useful to train a classification problem with C classes.\n","        loss = F.nll_loss(output, target) #타겟은 정답인 label\n","        #dloss/dx for every Variable \n","        loss.backward() #뉴럴 네트워크를 얼만큼 업데이트 해야하는가\n","        #print(loss.data)\n","        #to do a one-step update on our parameter.\n","        optimizer.step()\n","        #Print out the loss periodically. \n","        if batch_idx % args['log_interval'] == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.data))\n","\n","def test():\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    for data, target in test_loader:\n","        if args['cuda']:\n","            data, target = data.cuda(), target.cuda()\n","        data, target = Variable(data, volatile=True), Variable(target)\n","        output = model(data)\n","        test_loss += F.nll_loss(output, target, size_average=False).data # sum up batch loss\n","        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n","        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum() #정답 갯수\n","\n","    test_loss /= len(test_loader.dataset)\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q1yUb3qlHBM0","executionInfo":{"status":"ok","timestamp":1620815311523,"user_tz":-540,"elapsed":796,"user":{"displayName":"이건모","photoUrl":"","userId":"03575563892051424086"}}},"source":["train_data_reshaped1 = np.reshape(train_data[ :-1:2,:,:,:,:],(train_data.shape[0]//2, train_data.shape[2], train_data.shape[3], train_data.shape[4]))\n","train_label = np.squeeze(train_label)\n","train_loader = torch.utils.data.DataLoader( #데이터 로더는 데이터셋, 배치사이즈, 셔플을 이용해서 더 많은 기능을 제공\n","    MyDataset(torch.from_numpy(train_data_reshaped1), torch.squeeze(torch.from_numpy(train_label[:-1:2]))), #마이 데이터셋 객체화(데이터만 저장 된 객체)\n","    batch_size=args['batch_size'], shuffle=True, **kwargs)\n","train_data_reshaped2 = np.reshape(train_data[1:-1:2,:,:,:,:],(train_data.shape[0]//2-1, train_data.shape[2], train_data.shape[3], train_data.shape[4]))\n","test_loader = torch.utils.data.DataLoader( #트레인데이터를 다르게 했으므로 정확도가 100으로 안나온다\n","    MyDataset(torch.from_numpy(train_data_reshaped2), torch.squeeze(torch.from_numpy(train_label[1:-1:2]))),\n","    batch_size=args['test_batch_size'], shuffle=True, **kwargs)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"CibRu6Zb7FE4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620815363905,"user_tz":-540,"elapsed":51421,"user":{"displayName":"이건모","photoUrl":"","userId":"03575563892051424086"}},"outputId":"950c3cca-047b-462c-8e5f-9b23ba94c616"},"source":["model = Net()\n","if args['cuda']:\n","    model.cuda() #기본적으론 CPU에 올라가지만 이를 통해 GPU에 올릴 수도 있다\n","\n","optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=args['momentum'])\n","#어떻게 효과적으로 내려올 것인가?, loss func의 기울기를 보고 내려오는 방식\n","for epoch in range(1, args['epochs'] + 1):\n","    train(epoch)\n","    test()"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Train Epoch: 1 [0/1000 (0%)]\tLoss: 5.361429\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:73: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 18.0017, Accuracy: 8/999 (1%)\n","\n","Train Epoch: 2 [0/1000 (0%)]\tLoss: 2.360949\n","\n","Test set: Average loss: 15.0944, Accuracy: 19/999 (2%)\n","\n","Train Epoch: 3 [0/1000 (0%)]\tLoss: 0.144964\n","\n","Test set: Average loss: 6.7963, Accuracy: 42/999 (4%)\n","\n","Train Epoch: 4 [0/1000 (0%)]\tLoss: 0.050696\n","\n","Test set: Average loss: 4.4117, Accuracy: 102/999 (10%)\n","\n","Train Epoch: 5 [0/1000 (0%)]\tLoss: 0.030618\n","\n","Test set: Average loss: 4.5001, Accuracy: 106/999 (11%)\n","\n","Train Epoch: 6 [0/1000 (0%)]\tLoss: 0.012054\n","\n","Test set: Average loss: 4.4235, Accuracy: 107/999 (11%)\n","\n","Train Epoch: 7 [0/1000 (0%)]\tLoss: 0.012339\n","\n","Test set: Average loss: 4.5431, Accuracy: 92/999 (9%)\n","\n","Train Epoch: 8 [0/1000 (0%)]\tLoss: 0.004836\n","\n","Test set: Average loss: 4.4762, Accuracy: 108/999 (11%)\n","\n","Train Epoch: 9 [0/1000 (0%)]\tLoss: 0.073079\n","\n","Test set: Average loss: 4.5241, Accuracy: 111/999 (11%)\n","\n","Train Epoch: 10 [0/1000 (0%)]\tLoss: 0.031347\n","\n","Test set: Average loss: 4.4912, Accuracy: 108/999 (11%)\n","\n","Train Epoch: 11 [0/1000 (0%)]\tLoss: 0.002326\n","\n","Test set: Average loss: 4.4654, Accuracy: 117/999 (12%)\n","\n","Train Epoch: 12 [0/1000 (0%)]\tLoss: 0.007449\n","\n","Test set: Average loss: 4.4828, Accuracy: 112/999 (11%)\n","\n","Train Epoch: 13 [0/1000 (0%)]\tLoss: 0.004780\n","\n","Test set: Average loss: 4.5153, Accuracy: 110/999 (11%)\n","\n","Train Epoch: 14 [0/1000 (0%)]\tLoss: 0.002192\n","\n","Test set: Average loss: 4.4818, Accuracy: 107/999 (11%)\n","\n","Train Epoch: 15 [0/1000 (0%)]\tLoss: 0.001845\n","\n","Test set: Average loss: 4.5266, Accuracy: 112/999 (11%)\n","\n","Train Epoch: 16 [0/1000 (0%)]\tLoss: 0.008419\n","\n","Test set: Average loss: 4.5332, Accuracy: 111/999 (11%)\n","\n","Train Epoch: 17 [0/1000 (0%)]\tLoss: 0.001654\n","\n","Test set: Average loss: 4.5606, Accuracy: 111/999 (11%)\n","\n","Train Epoch: 18 [0/1000 (0%)]\tLoss: 0.002342\n","\n","Test set: Average loss: 4.5430, Accuracy: 112/999 (11%)\n","\n","Train Epoch: 19 [0/1000 (0%)]\tLoss: 0.002356\n","\n","Test set: Average loss: 4.5591, Accuracy: 108/999 (11%)\n","\n","Train Epoch: 20 [0/1000 (0%)]\tLoss: 0.004063\n","\n","Test set: Average loss: 4.8975, Accuracy: 90/999 (9%)\n","\n","Train Epoch: 21 [0/1000 (0%)]\tLoss: 0.001105\n","\n","Test set: Average loss: 4.5933, Accuracy: 102/999 (10%)\n","\n","Train Epoch: 22 [0/1000 (0%)]\tLoss: 0.001356\n","\n","Test set: Average loss: 4.5677, Accuracy: 109/999 (11%)\n","\n","Train Epoch: 23 [0/1000 (0%)]\tLoss: 0.001849\n","\n","Test set: Average loss: 4.5990, Accuracy: 109/999 (11%)\n","\n","Train Epoch: 24 [0/1000 (0%)]\tLoss: 0.004074\n","\n","Test set: Average loss: 4.5700, Accuracy: 106/999 (11%)\n","\n","Train Epoch: 25 [0/1000 (0%)]\tLoss: 0.001323\n","\n","Test set: Average loss: 4.5832, Accuracy: 114/999 (11%)\n","\n","Train Epoch: 26 [0/1000 (0%)]\tLoss: 0.001911\n","\n","Test set: Average loss: 4.6112, Accuracy: 110/999 (11%)\n","\n","Train Epoch: 27 [0/1000 (0%)]\tLoss: 0.005772\n","\n","Test set: Average loss: 4.6074, Accuracy: 111/999 (11%)\n","\n","Train Epoch: 28 [0/1000 (0%)]\tLoss: 0.003609\n","\n","Test set: Average loss: 4.6216, Accuracy: 109/999 (11%)\n","\n","Train Epoch: 29 [0/1000 (0%)]\tLoss: 0.001330\n","\n","Test set: Average loss: 4.6203, Accuracy: 106/999 (11%)\n","\n","Train Epoch: 30 [0/1000 (0%)]\tLoss: 0.000690\n","\n","Test set: Average loss: 4.6076, Accuracy: 108/999 (11%)\n","\n","Train Epoch: 31 [0/1000 (0%)]\tLoss: 0.001299\n","\n","Test set: Average loss: 4.6301, Accuracy: 116/999 (12%)\n","\n","Train Epoch: 32 [0/1000 (0%)]\tLoss: 0.000442\n","\n","Test set: Average loss: 4.6112, Accuracy: 111/999 (11%)\n","\n","Train Epoch: 33 [0/1000 (0%)]\tLoss: 0.015977\n","\n","Test set: Average loss: 4.6543, Accuracy: 107/999 (11%)\n","\n","Train Epoch: 34 [0/1000 (0%)]\tLoss: 0.001040\n","\n","Test set: Average loss: 4.6410, Accuracy: 115/999 (12%)\n","\n","Train Epoch: 35 [0/1000 (0%)]\tLoss: 0.001124\n","\n","Test set: Average loss: 4.6584, Accuracy: 110/999 (11%)\n","\n","Train Epoch: 36 [0/1000 (0%)]\tLoss: 0.000859\n","\n","Test set: Average loss: 4.6582, Accuracy: 111/999 (11%)\n","\n","Train Epoch: 37 [0/1000 (0%)]\tLoss: 0.001137\n","\n","Test set: Average loss: 4.7418, Accuracy: 106/999 (11%)\n","\n","Train Epoch: 38 [0/1000 (0%)]\tLoss: 0.001106\n","\n","Test set: Average loss: 4.6695, Accuracy: 110/999 (11%)\n","\n","Train Epoch: 39 [0/1000 (0%)]\tLoss: 0.000817\n","\n","Test set: Average loss: 4.6681, Accuracy: 115/999 (12%)\n","\n","Train Epoch: 40 [0/1000 (0%)]\tLoss: 0.001158\n","\n","Test set: Average loss: 4.6640, Accuracy: 106/999 (11%)\n","\n","Train Epoch: 41 [0/1000 (0%)]\tLoss: 0.000822\n","\n","Test set: Average loss: 4.7153, Accuracy: 109/999 (11%)\n","\n","Train Epoch: 42 [0/1000 (0%)]\tLoss: 0.000654\n","\n","Test set: Average loss: 4.6885, Accuracy: 103/999 (10%)\n","\n","Train Epoch: 43 [0/1000 (0%)]\tLoss: 0.001032\n","\n","Test set: Average loss: 4.6899, Accuracy: 109/999 (11%)\n","\n","Train Epoch: 44 [0/1000 (0%)]\tLoss: 0.000548\n","\n","Test set: Average loss: 4.6932, Accuracy: 108/999 (11%)\n","\n","Train Epoch: 45 [0/1000 (0%)]\tLoss: 0.001632\n","\n","Test set: Average loss: 4.6874, Accuracy: 111/999 (11%)\n","\n","Train Epoch: 46 [0/1000 (0%)]\tLoss: 0.001923\n","\n","Test set: Average loss: 4.7207, Accuracy: 115/999 (12%)\n","\n","Train Epoch: 47 [0/1000 (0%)]\tLoss: 0.003149\n","\n","Test set: Average loss: 4.7113, Accuracy: 106/999 (11%)\n","\n","Train Epoch: 48 [0/1000 (0%)]\tLoss: 0.000936\n","\n","Test set: Average loss: 4.7327, Accuracy: 110/999 (11%)\n","\n","Train Epoch: 49 [0/1000 (0%)]\tLoss: 0.000555\n","\n","Test set: Average loss: 4.7195, Accuracy: 109/999 (11%)\n","\n","Train Epoch: 50 [0/1000 (0%)]\tLoss: 0.000511\n","\n","Test set: Average loss: 4.7485, Accuracy: 111/999 (11%)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l8VWFKKc3V-N","executionInfo":{"status":"ok","timestamp":1620815455695,"user_tz":-540,"elapsed":938,"user":{"displayName":"이건모","photoUrl":"","userId":"03575563892051424086"}}},"source":["test_query_data_reshaped = np.reshape(test_query_data,(test_query_data.shape[0], test_query_data.shape[2], test_query_data.shape[3], test_query_data.shape[4]))\n","test_gallery_data_reshaped = np.reshape(test_gallery_data,(test_gallery_data.shape[0], test_gallery_data.shape[2], test_gallery_data.shape[3], test_gallery_data.shape[4]))\n","\n","test_query_loader = torch.utils.data.DataLoader(\n","    MyDataset(torch.from_numpy(test_query_data_reshaped)),\n","    batch_size=args['test_batch_size'], shuffle=False, **kwargs)\n","test_gallery_loader = torch.utils.data.DataLoader(\n","    MyDataset(torch.from_numpy(test_gallery_data_reshaped)),\n","    batch_size=args['test_batch_size'], shuffle=False, **kwargs)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"aq225LaF6gue","executionInfo":{"status":"ok","timestamp":1620815457875,"user_tz":-540,"elapsed":766,"user":{"displayName":"이건모","photoUrl":"","userId":"03575563892051424086"}}},"source":["import math\n","feature_extractor = torch.nn.Sequential(*list(model.children())[:-2])\n","\n","test_query_feature = np.zeros((test_query_data.shape[0], 512)) #conv1 -> batchnorm -> relu통과한 것\n","test_gallery_feature = np.zeros((test_gallery_data.shape[0], 512))\n","\n","cursor = 0\n","for data in test_query_loader:\n","  test_query_feature[cursor:min(cursor+args['test_batch_size'], test_query_data.shape[0]) ,:] = feature_extractor(data).detach().numpy().squeeze()\n","  cursor+=args['test_batch_size']\n","\n","cursor = 0\n","for data in test_gallery_loader:\n","  test_gallery_feature[cursor:min(cursor+args['test_batch_size'], test_gallery_data.shape[0]) ,:] = feature_extractor(data).detach().numpy().squeeze()\n","  cursor+=args['test_batch_size']\n"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"5YnCs3Yk5Jqv","executionInfo":{"status":"ok","timestamp":1620815543207,"user_tz":-540,"elapsed":990,"user":{"displayName":"이건모","photoUrl":"","userId":"03575563892051424086"}}},"source":["def normalized(a, axis=-1, order=2):\n","    l2 = np.atleast_1d(np.linalg.norm(a, order, axis))\n","    l2[l2==0] = 1\n","    return a / np.expand_dims(l2, axis)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"-32FVtss3PPZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620815569172,"user_tz":-540,"elapsed":1711,"user":{"displayName":"이건모","photoUrl":"","userId":"03575563892051424086"}},"outputId":"45f1dfff-373b-422d-a799-d387c54d310f"},"source":["print(test_query_feature.shape)\n","print(test_gallery_feature.shape)\n","nn_idx_deep = getNearestNeibor(normalized(test_query_feature, axis=1, order=2), normalized(test_gallery_feature, axis=1, order=2))\n","#normalization을 통해 성능이 좋아진다. 피쳐들이 나타내는 정보들의 성능이 좋아지기 때문에 왠만해선 성능이 높아진다.\n","#nn_idx_deep = getNearestNeibor(test_query_feature, test_gallery_feature)\n","print(test_query_data.shape)\n","#print(np.sum(test_query_label == test_gallery_label[np.int64(nn_idx_deep)]))\n","#print(np.sum(test_query_label == test_gallery_label[np.int64(nn_idx)]))\n","#nn_idx_rand = np.random.randint(1,100,1000)\n","#print(np.sum(test_query_label == test_gallery_label[np.int64(nn_idx_rand)]))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["(1000, 512)\n","(100, 512)\n","(1000, 1, 512, 1, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aHpCLdYE31Fp","executionInfo":{"status":"ok","timestamp":1620815644222,"user_tz":-540,"elapsed":638,"user":{"displayName":"이건모","photoUrl":"","userId":"03575563892051424086"}}},"source":["from sklearn.neighbors import NearestNeighbors\n","nbrs = NearestNeighbors(n_neighbors=1).fit(normalized(test_gallery_feature, axis=1, order=25))\n","distances, indices = nbrs.kneighbors(normalized(test_query_feature, axis=1, order=25))\n","#오더가 높아질 수록 성능 내려가는 경향 l1, l2여야 성능이 좋은 경향을 보인다. 보통 l2가 많이 쓰인다.\n","#print(np.sum(test_query_label == test_gallery_label[np.int64(indices.squeeze())]))\n"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RhL6RaN3AElN"},"source":["# 새 섹션"]}]}